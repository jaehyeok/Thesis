In order to test a compatibility of observed data with a hypothesis, 
one performs statistical hypothsis tests. In the Higgs search or 
other searches in general, there are two hypotheses to be tested: 
a hypothsis that Higgs exists and a hypothesis that Higgs does not exist. 
For a quantitative analysis, we first construct a test statistic. 
It is a function of expected signal($s$) and background yields($b$),
and the observed data. Then, probability density functions(\textit{pdf}) for 
each hypothesis are constructed by pseudo-data or analytic functions. 
After that, the compatibility of data with each hypothesis is estimated
in terms of p-value, the probability for the \textit{pdf} to have the measurement 
at observed data or greater. 

One complexity to consider is that the 
expected yields, $s$ and $b$, are subject to change by many sources 
discussed in chapter~\ref{ch:systematics}. These systematic uncertainties 
are incorporated to the likelihood by adding \textit{pdf} for each systematic source. 
The \textit{pdf} is constructed by re-interpretating the \textit{pdf}, 
$\rho(\theta | \tilde{\theta})$, using the Bayes' theorem 
\begin{eqnarray} 
\rho(\theta | \tilde{\theta}) 
\sim 
p(\tilde{\theta} | \theta) \cdot \pi_\theta \left( \theta \right)  
\end{eqnarray} 
where $\pi_\theta \left( \theta \right)$ is the prior for which 
we use a flat function. This re-interpretation allows one to 
represent the systematic errors in a frequentist context~\cite{combination_stat}. 

This chapter discusses in detail the statistical procedure of the exclusion 
and the discovery of the SM Higgs boson.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exclusion of SM Higgs boson}
\label{sec:stat_exclusion}

The procedure of constructing the likelihood and the probability density function 
which is agreed between ALTAS and CMS collaborations is
described in detail in the reference~\cite{combination_stat}.

%\begin{itemize}
%
%\item{\textbf{Step 1 : Construct likelihood function based on Poisson statistics} } \\
The first step for the \textit{pdf} construction is to define 
a likelihood function,  
\begin{eqnarray} 
\mathcal{L} ( X | \mu, \theta) 
\, = \,
\prod_{i}^{N_{bin}} \frac{ \left( \mu s_i(\theta) + b_i(\theta) \right)^{X_i}}{X_i!} 
\, e^{ - \mu s_i(\theta) - b_i(\theta) }   \times
\prod_{j}^{N_{nuisance}} p\left( \tilde{\theta_j} | \theta_j \right)
\end{eqnarray}
where $X=\left\{X_i\right\}$ is a set of measurements which can be   
the real data from measurement or a pseudo-data generated 
to construct the $pdf$s on a given hypothesis, $N_{bin}$ is the number of 
measurements which corresponds to the number of bins or categories, 
$\mu$ is the signal strength (signal strength modifier),
$\theta$ is the nuisance parameter, 
$s_i(\theta)$ and $b_i(\theta)$ are the expected signal and background 
yields, respectively, in the $i^{th}$ bin or category,
$p\left( \tilde{\theta_j} | \theta_j \right)$ is the \textit{pdf} for 
$\theta_j$ which is constructed from auxiliary measurements or some theoretical  
assumptions, and $\tilde{\theta_j}$ is the measured or assumed value of $\theta$. 

%
%\item{\textbf{Step 2 : Construct a test static, $\tilde{q}_\mu$} }  \\
According to the Neyman-Pearson lemma~\cite{neymanpearson}, 
when performing a hypothesis test between two hypotheses,
the ratio of two likelihoods constructed by the two hypotheses
%\textit{i.e. signal+backgrond} and \textit{background-only}, 
is the most powerful discriminator. Instead of the ratio itself, 
the log of the ratio is taken because of a number of advantages
\footnote{Log converts multiplication of likelihoods into linear summation. 
Terms in exponent becomes a multiplication factor.}.  
At the LHC, due to its asymptotic properties which is described in detail 
in the reference~\cite{cowan_asimov}, 
the profile log-likelihood ratio (LLR) is used as a test statistic.    
The profile log-likelihood is constructed using values of nuisance parameters 
that maximize the likelihood function. By varing a nuisance parameter($\theta_i$)
according to the constraint function($p\left( \tilde{\theta_i} | \theta_i \right)$) 
a new central value along with new uncertainty is determined and used 
for statistical interpretation. However, there can be a case where 
some nuisance parameters are over-constrained, \textit{i.e.} becoming too 
small compared to the estimated value, because of high statistics in data. 
Therefore, it is important to examine the post-fit nuisance parameters 
and make sure that over-contraining some of them does not affect the final 
results. This issue is discussed in section~\ref{sec:postfit-ana}.

The functional form of the statistic is 
\begin{eqnarray} 
\tilde{q}_\mu 
= 
\left\{ \begin{array}{l l}
\displaystyle
-2 \ln \frac{\mathcal{L} ( X | \mu, \hat{\theta}_\mu)}
            {\mathcal{L} ( X | \hat{\mu}, \hat{\theta})}  
            & \quad \quad \quad \quad \textrm{if } 0 \le \hat{\mu} \le \mu \\
0           & \quad \quad \quad \quad \textrm{otherwise}
\end{array} \right.
\end{eqnarray}  
where $\hat{\theta}_\mu$ is the best-fit value of $\theta$ for a given $\mu$, 
$\hat{\mu}$ and $\hat{\theta}$ are the best-fit values of 
$\mu$ and $\theta$, respectively, from the global fit on data.
The requirement $0 \le \hat{\mu}$ is imposed because the signal rate must be positive. 
The requirement $\hat{\mu} \le \mu$ constrains $\mu$ to one-sided confidence level. 
This also means that the region, $\mu < \hat{\mu}$, is not considered  
more incompatible than the data observed, $\hat{\mu}$. This region 
is not tested for setting upper limits.
%For example, if $\hat{\mu}=1$ then we do not test for $\mu=0.5$ 
%because $\mu=0.5$ is not less compatible than  
%
%\item{\textbf{Step 3 : Find the observed values}}  \\

%Then, we find the observed values of the test static($\tilde{q}_\mu^{obs}$) 
%and the nuisance parameters($\hat{\theta}_\mu^{obs}$ and $\hat{\theta}_0^{obs}$)
%that maximize the likelihoods. 
%$\mathcal{L} ( X | \mu, \hat{\theta}_\mu)$ is used to calculate
%$\tilde{q}_\mu^{obs}$ and $\hat{\theta}_\mu^{obs}$ for \textit{signal + background}
%hypothesis with the given signal strength modifier, $\mu$,
%and $\mathcal{L} ( X | 0, \hat{\theta}_0)$ is used to get $\hat{\theta}_0^{obs}$
%for \textit{background-only} hypothesis.    
%
Then, we construct the \textit{pdf}s based on the two hypotheses we 
want to test, the \textit{signal + background} and the \textit{background-only} hypotheses.
We first find the observed(profiled) values of the nuisance 
parameters($\hat{\theta}_\mu^{obs}$ and $\hat{\theta}_0^{obs}$),
and calculate the values of the test statistic($\tilde{q}_\mu^{obs}$ 
and $\tilde{q}_0^{obs}$) assuming the two hypotheses.
%\item{\textbf{Step 4 : Construct \textit{pdf}s for \textit{signal + background} 
%       and \textit{background-only} hypotheses} } \\
Using the profiled nuisance parameters, $\hat{\theta}_\mu^{obs}$ and $\hat{\theta}_0^{obs}$, 
Monte-Carlo toys are generated to construct \textit{pdf}s for \textit{signal + background}
and \textit{background-only} hypotheses, 
$f\left( \hat{q}_\mu | \mu, \hat{\theta}_\mu^{obs} \right)$ and 
$f\left( \hat{q}_\mu | 0, \hat{\theta}_0^{obs} \right)$, respectively.
Since generating toys requires a large consumption of CPU power, 
we can take an advantage of the fact that $\tilde{q}_\mu$ follows 
a well-defined formula in the asymptotic limit~\cite{cowan_asimov}. 
%This is true if $\hat{\mu}>0$ \textcolor{red}{WHY not equal sign here?} 
%is not applied. But, even with the requirement $\hat{\mu}>0$, 
The $\tilde{q}_\mu$ can be calculated analytically
\begin{eqnarray} 
f\left( \tilde{q}_\mu | \mu \right) 
= 
\frac{1}{2} \delta \left( \tilde{q}_\mu \right)  + 
\left\{ \begin{array}{l l}
\displaystyle
\frac{1}{2\sqrt{2\pi}} \frac{1}{\sqrt{\tilde{q}_\mu}}  e^{-\tilde{q}_\mu/2}
   & \quad \quad \quad 0 < \tilde{q}_\mu \le \mu^2/\sigma^2 \\
\frac{\sigma}{2\sqrt{2\pi}\mu} 
   \textrm{exp}\left[-\frac{1}{2} \frac{(\tilde{q}_\mu^2+\mu^2/\sigma^2)^2}{(2\mu/\sigma)^2}   \right]
   & \quad \quad \quad \tilde{q}_\mu > \mu^2/\sigma^2 
\end{array} \right.
\end{eqnarray} 
where $\delta(\tilde{q}_\mu)$ is the Dirac delta function and 
$\displaystyle \sigma^2 = \frac{\mu^2}{q_{\mu,A}}$ 
is the uncertainty on the test statistic evaluated using the Asimov 
dataset~\cite{cowan_asimov}. 
The Asimov dataset is a representative dataset made with the expected 
nuisance parameters. 
In this analysis the expected sensitivity(exclusion and significance) is calculated 
in the asymptotic limit.
Similarly, the $pdf$ for the \textit{background-only} hypothesis,
$f\left( \tilde{q}_\mu | 0 \right)$, can be obtained 
using the same technique. 
%The two $pdf$s are used to construct a measure for hypothesis test.

%
%\item{\textbf{Step 5 : Calculated statistical significance of observation }}  \\
For the measurement X, the test static($\tilde{q}_\mu^{obs}$) can be used to 
test the significance of the observation. The LHC uses the \CLs\ 
method~\cite{Read:451614,Junk:1999kv} that was developed by LEP 
to mitigate the problem of excluding a model one is not sensitive to. 
The p-value of the testing parameter is penalized by the insensitivity 
to distinguish the two hypotheses.  
The $\textrm{CL}_\textrm{s}$ is defined by two p-values, $p_\mu$ and $1-p_b$. 
The $p_\mu$ is the p-value with \textit{signal + background} hypothesis, and defined by 
\begin{eqnarray} 
p_\mu
&=& P\left(\tilde{q}_\mu \ge \tilde{q}_\mu^{obs} | signal+background \right)  \\
&=& \int^{\infty}_{\tilde{q}_\mu^{obs}}  f\left(  \tilde{q}_\mu | \mu \right) d\tilde{q}_\mu.
\end{eqnarray} 
A large value of $p_\mu$ represents a high chance that observation is compatible 
with the hypothesized signal strength, $\mu$.
The $1-p_b$ is the p-value with \textit{background-only} hypothesis, and defined by 
\begin{eqnarray} 
1-p_b
&=& P\left(\tilde{q}_\mu \ge \tilde{q}_\mu^{obs} | background-only \right)  \\
&=& \int^{\infty}_{\tilde{q}_\mu^{obs}}  f\left(  \tilde{q}_\mu | 0 \right) d\tilde{q}_\mu.
\end{eqnarray} 
A large value of $1-p_b$ represents a high chance that observation is compatible 
with the \textit{background-only} hypothesis, $\mu=0$. Thus, if data is 
\textit{signal + background}-like the $p_b$ is small. 
The $\textrm{CL}_\textrm{s}$ is defined as a ratio of the two p-values 
\begin{eqnarray} 
\textrm{CL}_\textrm{s} \left( \mu \right) = \frac{p_\mu}{1 - p_b}.   
\end{eqnarray} 

Now we set the limit on the signal strength to test the 
compatibility of data with the SM Higgs hypothesis. 
The upper limit on the $\mu$ at $\alpha$\% confidence level is the value of $\mu$  
which gives $\textrm{CL}_\textrm{s} = 1 - \alpha \%$. Writing for $\mu$, we have 
\begin{eqnarray} 
\mu^{\alpha~\%} = \textrm{CL}_\textrm{s}^{-1} ( 1-\alpha\%).
\end{eqnarray} 
In this case, the \textit{signal+background} hypothesis with $\mu > \mu^{\alpha \%}$
is regarded as incompatible with data, and excluded at $\alpha\%$ $\textrm{CL}_\textrm{s}$ 
confidence level.

When the expected limit is evaluated,  
it is useful to know how $\mu^{\alpha \%}$ varies 
because even though the true $\mu$ (call it $\mu'$) is correct, 
the data we actually observe can have a different value by statistical fluctuation.  
In the asymptotic limit, the \CLs\ is given by~\cite{combination_stat}
\begin{eqnarray} 
\CLs 
= 1 - \alpha~\% 
= \frac{1 - \Phi\left(\sqrt{q_\mu}\right)}{\Phi\left(\sqrt{q_{\mu,A}} - \sqrt{q_\mu}\right)}   
\end{eqnarray} 
where $\Phi$ is a cumulative distribution of standard normal distribution. 
Using the relations, $\sqrt{q_\mu} = \frac{\mu - \hat{\mu}}{\sigma}$   
and $\sqrt{q_{\mu,A}} = \frac{\mu}{\sigma}$~\cite{cowan_asimov}, 
we have 
\begin{eqnarray} 
1 - \alpha~\% 
&=&   
\frac{1 - \Phi\left(\frac{\mu - \hat{\mu}}{\sigma} \right)}
       {\Phi\left( \frac{\mu}{\sigma} - \frac{\mu - \hat{\mu}}{\sigma} \right)} \\    
&=&   
\frac{1 - \Phi\left(\frac{\mu}{\sigma} - \frac{\hat{\mu}}{\sigma} \right)}
     {\Phi\left( \frac{\hat{\mu}}{\sigma} \right)} \\    
&=&   
\frac{1 - \Phi\left(\frac{\mu}{\sigma} - N \right)}
     {\Phi\left( N \right)}.    
\end{eqnarray}
where N indicates the size of the error band in the unit of $\sigma$.
Solving this equation for $\mu$, the median and the expected error bands are given by 
\begin{eqnarray} 
\mu^{\alpha~\%} 
= 
\sigma \left[ \Phi^{-1} \left( 1 - \Phi\left( N \right) 
\left( 1 - \alpha \right)  \right) + N \right].
\end{eqnarray} 
Note that putting $N=0$ gives the median upper limit of $\mu$ 
in the asymptotic limit. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discovery of a New Boson}
\label{sec:stat_significance}

In order to claim a discovery of a new particle, we test the compatibility of 
the \textit{background-only} hypothesis against data. A large deviation in 
terms of p-value will indicate that the observed data is not compatible 
with the \textit{background-only} hypothesis. 
Thus, something "new'' needs to be taken into account. 

The test can be performed by generating many pseudo-datasets assuming the 
\textit{background-only} hypothesis, and construct a \textit{pdf} 
of the chosen test statistic. The choice of test statistic for 
this test is  
\begin{eqnarray} 
q_0
=
\left\{ \begin{array}{l l}
\displaystyle
-2 \ln \frac{\mathcal{L}( X | 0, \hat{\theta}_0)}
            {\mathcal{L}( X | \hat{\mu}, \hat{\theta}_\mu)} 
             & \qquad \textrm{ with } \hat{\mu} \ge 0 \\   
0 
             & \qquad \textrm{ with } \hat{\mu} < 0    
\end{array} \right.
\end{eqnarray} 
We don't consider downward fluctuations in data($\hat{\mu} < 0$) as an 
compatibility with data. The downward fluctuations 
is more likely due to systematic uncertainties such as over-estimation 
of backgrounds. So, in case of $\hat{\mu} < 0$ the test statistic, $q_0$, is set 0. 

Given the test statistic, we construct the \textit{pdf}, $f(q_0|0,\hat{\theta}_0)$, 
with many pseudo-datasets generated assuming \textit{background-only} hypothesis.
The p-value, $q_0^{obs}$, is given by 
\begin{eqnarray} 
p_0
&=& P \left( q_0 \ge q_0^{obs} | background-only \right)  \\
&=& \int^{\infty}_{ q_0^{obs} }  f\left( q_0 | 0, \hat{\theta}_0 \right) dq_0.
\end{eqnarray} 
The calculated p-value can be converted into an one-sided %(\textcolor{red}{Why one-sided?}) 
significance Z by finding Z that satisfies 
\begin{eqnarray} 
p-value 
= 
\int^{\infty}_{Z} \frac{1}{\sqrt{2\pi}} e^{ -\frac{x^2}{2}} dx.   
\end{eqnarray} 
This is the convention in the particle physics community 
when expressing an evidence or discovery of a new particle~\cite{Beringer:1900zz}.

In the asymptotic limit, the \textit{pdf} is given by a mixture of 
a Dirac delta function and a chi-square distribution for one 
degree of freedom~\cite{combination_stat}
\begin{eqnarray} 
f\left(q_0 | 0, \hat{\theta}_0 \right) 
= 
\frac{1}{2} \delta \left(q_0\right)  
+ 
\frac{1}{2\sqrt{2\pi}\sqrt{q_0}} e^{-\frac{q_0}{2}}.
\end{eqnarray}
In this case p-value can be obtained by 
\begin{eqnarray}
p_0 = 1 - \Phi \left( \sqrt{q_0} \right).
\end{eqnarray} 
Using this equation, the significance is given by  
\begin{eqnarray} 
Z_0 = \Phi^{-1} \left( 1 - p_0 \right) = \sqrt{q_0}.
\end{eqnarray} 

In this analysis(and many other analyses as well), 
the sensitivity to the discovery of a new particle is 
measured by the expected significance. In this case, the $q_0$ 
is calculated using $\mu = 1$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Hypothesis Separation} 
%Once a particle is observed, it is important to test its properties 
%such as mass, spin and parity, \textit{etc}. It is shown that the full leptonic 
%WW analysis is sensitive to distinguish between SM model hypothesis and a 
%graviton-like spin-2 resonance which couples to the dibosons through minimal 
%couplings~\cite{Bolognesi:2012mm}. 

%We perform MLL fit to each hypothesis to extract the signal strength and 
%background contributions. The same likelihood function as SM Higgs search 
%is used. For a given dataset, MLL fits for both hypotheses are performed. 
%In the likelihood calculation, the signal strength is allowed to float as 
%SM Higgs search. The signal strength and nuisance parameters of the two 
%hypotheses are treated independently. The difference in the best-fit likelihoods 
%\begin{eqnarray}
%q
%=
%-2 \ln \frac{\mathcal{L}_{2^+_{min}}}{\mathcal{L}_{0^+}}
%=
%-2 \ln \frac{\mathcal{L}\left( X | \hat{\mu}_{2^+_{min}}, \hat{\theta}_{2^+_{min}} \right)}
%            {\mathcal{L}\left( X | \hat{\mu}_{0^+}, \hat{\theta}_{0^+} \right)}
%\end{eqnarray} 
%is used to quantify the consistenby of data to the two hypothesis.   

